# EchoVision: Smart AI Assistance for Visually Impaired

EchoVision is an AI-powered mobile application developed to support visually impaired individuals by providing real-time voice interaction, object detection, and communication features. It enables users to interact with their environment and smartphone using voice commands only, promoting accessibility and independence.

## Features

- Voice-activated commands for hands-free usage
- Real-time object detection using AI-based vision technology
- Make phone calls and send messages using voice prompts
- Add and manage contacts through voice input
- Seamless integration with the deviceâ€™s contact list

## Project Objectives

- Provide assistance in navigating surroundings through voice feedback and object detection
- Allow communication using voice-driven call and messaging functions
- Simplify contact management without requiring visual interaction
- Offer an intuitive and inclusive interface designed specifically for visually impaired users

## Technologies Used

- Android Studio
- Python or Kotlin or Java (depending on implementation)
- TensorFlow, OpenCV for object detection
- Google Text-to-Speech and Speech Recognition APIs

## How It Works

1. User speaks commands to the app
2. The app identifies objects in the environment and provides audio descriptions
3. User can place calls or send messages via voice
4. Contacts can be added and accessed through speech input

## Target Users

This application is developed for visually impaired users who wish to navigate their surroundings and use smartphone features independently.

## Contributions

Suggestions and contributions are welcome. Fork the repository and submit a pull request if you'd like to collaborate.

Let's work together to build accessible technology for everyone.

